{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/google_gemma2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "TensorFlow version 2.17.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n",
      "Torch version 2.4.1 has not been tested with coremltools. You may run into unexpected errors. Torch 2.4.0 is the most recent version that has been tested.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import coremltools as ct\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_path = \"coreml_3B_INT4.mlpackage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"meta-llama/Llama-3.2-3B-Instruct\", token=\"\"\n",
    "    )\n",
    "\n",
    "mlmodel_fp16 = ct.models.MLModel(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"hello world!\", return_tensors='np')\n",
    "\n",
    "tok = inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128000  15339   1917      0    320  16225   4488    596     83     11\n",
      "     719    358    617   1027   7633    439]]\n"
     ]
    }
   ],
   "source": [
    "st_len = tok.shape[-1]\n",
    "\n",
    "state = mlmodel_fp16.make_state()  # 루프 내에서 상태 초기화\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    mask = np.full((1, st_len:=st_len+1), -1e9)\n",
    "    mask = np.triu(mask, k=1)\n",
    "    mask = np.hstack(\n",
    "        [np.zeros((1, 1)), mask]\n",
    "    )[None, None, :, :]\n",
    "\n",
    "    \n",
    "    input_dict = {\n",
    "        'input_ids': tok.astype(np.int32),\n",
    "        'causal_mask': mask.astype(np.int32)\n",
    "\n",
    "    }\n",
    "\n",
    "    preds = mlmodel_fp16.predict(input_dict, state=state)\n",
    "    \n",
    "    logits = preds['logits']\n",
    "    pre_toks = np.argmax(logits[0], axis=-1)\n",
    "\n",
    "    tok = np.concatenate([tok, [[pre_toks]]], axis= 1)\n",
    "\n",
    "print(tok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google_gemma2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
